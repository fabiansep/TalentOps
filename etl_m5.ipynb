{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEqd7giRCT1dHXGVDLGcEH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiansep/TalentOps/blob/main/etl_m5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JMJ4EY6ObFJs"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler('etl_pipeline.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "\n",
        "logger = logging.getLogger('etl_pipeline')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RobustETLPipeline:\n",
        "    def __init__(self, db_path='etl_database.db'):\n",
        "        self.db_path = db_path\n",
        "        self.logger = logging.getLogger('etl_pipeline')\n",
        "        self.metrics = {'processed': 0, 'errors': 0, 'start_time': None}\n",
        "\n",
        "    def run_pipeline(self):\n",
        "        self.metrics['start_time'] = pd.Timestamp.now()\n",
        "        self.logger.info(\"=== INICIANDO PIPELINE ETL ROBUSTO ===\")\n",
        "\n",
        "        try:\n",
        "            # Fase 1: Extracción con reintentos\n",
        "            data = self.extract_with_retry()\n",
        "\n",
        "            # Fase 2: Transformación con validaciones\n",
        "            transformed_data = self.transform_with_validation(data)\n",
        "\n",
        "            # Fase 3: Carga con transacciones\n",
        "            self.load_with_transaction(transformed_data)\n",
        "\n",
        "            self.report_success()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.report_failure(e)\n",
        "            raise\n",
        "\n",
        "    def extract_with_retry(self):\n",
        "        \"\"\"Extracción con estrategia de reintentos\"\"\"\n",
        "        max_retries = 3\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                self.logger.info(f\"Intento de extracción #{attempt + 1}\")\n",
        "\n",
        "                # Simular extracción (reemplazar con lógica real)\n",
        "                data = pd.DataFrame({\n",
        "                    'id': range(1, 101),\n",
        "                    'valor': [x * 1.1 for x in range(1, 101)],\n",
        "                    'categoria': ['A', 'B', 'C'] * 33 + ['A']\n",
        "                })\n",
        "\n",
        "                self.logger.info(f\"Extracción exitosa: {len(data)} registros\")\n",
        "                return data\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Intento #{attempt + 1} falló: {e}\")\n",
        "                if attempt == max_retries - 1:\n",
        "                    raise e\n",
        "                time.sleep(1)  # Esperar antes de reintentar\n",
        "\n",
        "    def transform_with_validation(self, data):\n",
        "            \"\"\"Transformación con validaciones y logging detallado\"\"\"\n",
        "            self.logger.info(\"Iniciando transformación\")\n",
        "            original_count = len(data)\n",
        "\n",
        "            try:\n",
        "                # Validación 1: Datos no nulos\n",
        "                if data.isnull().any().any():\n",
        "                    null_counts = data.isnull().sum()\n",
        "                    self.logger.warning(f\"Valores nulos encontrados: {null_counts[null_counts > 0].to_dict()}\")\n",
        "\n",
        "                # Transformación 1: Limpiar datos\n",
        "                data_clean = data.dropna()\n",
        "\n",
        "                # Transformación 2: Crear nuevas columnas\n",
        "                data_clean = data_clean.copy()  # Evitar SettingWithCopyWarning\n",
        "                data_clean['valor_cuadrado'] = data_clean['valor'] ** 2\n",
        "                data_clean['categoria_normalizada'] = data_clean['categoria'].str.upper()\n",
        "\n",
        "                # Validación 2: Resultados razonables\n",
        "                if (data_clean['valor_cuadrado'] < 0).any():\n",
        "                    raise ValueError(\"Valores cuadrados negativos detectados\")\n",
        "\n",
        "                self.logger.info(f\"Transformación exitosa: {original_count} -> {len(data_clean)} registros\")\n",
        "                return data_clean\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error en transformación: {e}\")\n",
        "                raise\n",
        "    def load_with_transaction(self, data):\n",
        "        \"\"\"Carga con soporte transaccional y rollback\"\"\"\n",
        "        self.logger.info(\"Iniciando carga a base de datos\")\n",
        "\n",
        "        with sqlite3.connect(self.db_path) as conn:\n",
        "            try:\n",
        "                # Iniciar transacción\n",
        "                conn.execute('BEGIN TRANSACTION')\n",
        "\n",
        "                # Crear tabla si no existe\n",
        "                conn.execute('''\n",
        "                    CREATE TABLE IF NOT EXISTS datos_transformados (\n",
        "                        id INTEGER PRIMARY KEY,\n",
        "                        valor REAL,\n",
        "                        categoria TEXT,\n",
        "                        valor_cuadrado REAL,\n",
        "                        categoria_normalizada TEXT\n",
        "                    )\n",
        "                ''')\n",
        "\n",
        "                # Limpiar datos previos (estrategia replace)\n",
        "                conn.execute('DELETE FROM datos_transformados')\n",
        "\n",
        "                # Insertar datos\n",
        "                data.to_sql('datos_transformados', conn, index=False, if_exists='append')\n",
        "\n",
        "                # Commit transacción\n",
        "                conn.commit()\n",
        "\n",
        "                self.logger.info(f\"Carga exitosa: {len(data)} registros insertados\")\n",
        "\n",
        "            except Exception as e:\n",
        "                # Rollback automático por context manager\n",
        "                self.logger.error(f\"Error en carga, ejecutando rollback: {e}\")\n",
        "                raise\n",
        "    def report_success(self):\n",
        "        \"\"\"Reportar métricas de éxito\"\"\"\n",
        "        duration = pd.Timestamp.now() - self.metrics['start_time']\n",
        "        self.logger.info(\"=== PIPELINE ETL COMPLETADO EXITOSAMENTE ===\")\n",
        "        self.logger.info(f\"Duración total: {duration}\")\n",
        "        self.logger.info(f\"Registros procesados: {self.metrics.get('processed', 0)}\")\n",
        "\n",
        "    def report_failure(self, error):\n",
        "        \"\"\"Reportar detalles de fallo\"\"\"\n",
        "        duration = pd.Timestamp.now() - self.metrics['start_time']\n",
        "        self.logger.error(\"=== PIPELINE ETL FALLÓ ===\")\n",
        "        self.logger.error(f\"Duración hasta fallo: {duration}\")\n",
        "        self.logger.error(f\"Error: {error}\")"
      ],
      "metadata": {
        "id": "rcrVqlovbb57"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Ejecutar pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    pipeline = RobustETLPipeline()\n",
        "    pipeline.run_pipeline()\n",
        "\n",
        "    # Verificar resultados\n",
        "    with sqlite3.connect('etl_database.db') as conn:\n",
        "        result = pd.read_sql('SELECT COUNT(*) as registros FROM datos_transformados', conn)\n",
        "        print(f\"Registros en base de datos: {result.iloc[0,0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdZbhDFzbzJS",
        "outputId": "341ea876-45af-4327-f63c-83fb29a4b10c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registros en base de datos: 100\n"
          ]
        }
      ]
    }
  ]
}